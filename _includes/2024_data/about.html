<!-- About Section -->
<section id="about">
    <div class="container">
        <div class="row">
            <div class="col-lg-12 text-center">
                <h2 class="section-heading">About</h2>
                <h3 class="section-subheading text-muted"></h3>
            </div>
        </div>
        <div class="row">
            <h2 class="first">About ICAA 2024</h2>            
            
            <p>
                The 3rd Conference on Assured Autonomy (ICAA'24) will take place from 
                October 10 - 11, 2024 at the Vanderbilt University, Nashville, Tennessee, USA.

                ICAA seeks contributions on all aspects of assurance for AI and autonomy, including safety, security, and 
                privacy in autonomous systems. Papers that encourage the discussion and exchange of 
                experimental and theoretical results, novel designs, and works in progress are preferred. 
                Topics of interest include (but are not limited to) AI/Autonomy Safety, and Security and Privacy.
            </p>
        </div>
	    
    </div>
</section>

<section id="dates">
	<div class="container">
        <div class="row">
            <div class="col-lg-12 text-center">
                <h2 class="section-heading">Important Dates</h2>
                <h3 class="section-subheading text-muted"></h3>
		    
            <p>
                <b>Paper submission deadline: Aug 7, 2024 </b> (Anywhere on Earth) <br>
                <b>Acceptance notification: Sep 7, 2024 </b><br>	   
                <b>Publication-ready Papers Due: <s>Sep 17, 2024</s> Sep 26, 2024</b><br>
                <b>Early Registration Deadline: <s>Sep 17, 2024</s> Sep 27, 2024</b><br>
                <b>Author Registration Deadline: <s>Sep 17, 2024</s> Sep 27, 2024</b><br>
            </p>
            </div>
        </div>
    </div>
</section>

<section id="cfc" class="bg-light-gray">
    
<!--background color-->
<script type="text/javascript">
   document.write ('<body style="background: Gainsboro; background-attachment: fixed;">')
</script>

<div class="container">
    <div class="row">
            <div class="col-lg-12 text-center">
                <h2 class="section-heading">Call for Papers</h2>
                <h3 class="section-subheading text-muted"></h3>
            </div>
        </div>
    <div class="row">
        <p>
The International Conference on Assured Autonomy (ICAA) plans to address the gap that exists between theory-heavy artificially intelligent autonomous systems and the privacy, security, and safety of their real-world implementations. Advances in machine learning (ML) and artificial intelligence (AI) have shown great promise in algorithms and techniques for automating complex decision-making processes across transportation, robotics, critical infrastructure, and cyber infrastructure domains. Practical implementations of these algorithms require significant systems engineering and integration support for safe, trusted, and assured operations, especially as they integrate with the physical world. This need for assurance is further challenged by AI safety, security, privacy, responsibility, bias, and alignment issues.

The focus of this conference is the: (1) Design of Assured and Safe Systems with AI and Autonomy, (2) Real-world Studies, Deployments and Industry Uses of Assured AI and Autonomy (3) Methods for Testing and Assuring AI and AI-enabled Autonomous Systems, and (4) Security and Privacy of AI and Autonomous Systems, which includes methods to detect, respond, mitigate, and recover resiliently to violations in safety, security, and privacy, and trust. 
            
            </p>
            <h2> Topics and types of contributions </h2>
            <p>
ICAA seeks new methodologies and contributions as well as applications and studies of all aspects of AI safety, security, and assurance in autonomous systems. Papers that encourage the discussion and exchange of experimental and theoretical results, novel designs, real-world uses, case studies and works in progress are requested. Both full papers (up to 10 pages) and working papers (up to 4 pages) will be accepted. Topics of interest include (but are not limited to):
                <p><strong>Design for Assured and Safe Autonomy</strong></p>
    
    <ul>
<li><p>	Safe-by-construction methods for autonomous systems</p></li>
<li><p>
Formally verified AI and autonomy
</p></li>
<li><p>
Neuro-symbolic learning and reasoning for assured, resilient autonomy
</p></li>
<li><p>
Systems that learn and adapt in the field
</p></li>
<li><p>
Sim-to-real transfer for assured AI and autonomy
</p></li>
<li><p>Runtime assurance and monitoring</p>
</li>
<li>
<p>Safe learning and control for autonomous and AI-enabled systems</p>
</li>
<li>
<p>Real-world studies, uses, and design considerations of AI for autonomous systems</p>
</li>
    </ul>
    
    <p><strong>Methods for Testing and Assuring AI and Autonomy</strong></p>
    <ul>
<li><p>
Explainable and interpretable AI-enabled systems
</p></li>
<li><p>
Alignment and safety of AI and autonomous systems
</p></li>
<li><p>
Standards, ethics, and policies for autonomy and AI to meet responsible AI principles
</p></li>
<li><p>
Verification, validation, testing, and assurance of systems with AI and autonomy
</p></li>
<li><p>
	Evaluating safety of autonomous systems according to their potential risks and vulnerabilities
</p></li>
<li><p>
	Test, evaluation, certification, and assurance of autonomous AI systems
</p></li>
<li><p>
	Modeling and simulation, virtual constructive and live testing challenges for AI and autonomous systems
</p></li>
<li><p>
	Safety, evaluation, and assurance of human-autonomy teaming
</p></li>
<li><p>
	Evaluation and safety of foundation models
</p></li>
<li><p>
	Lessons learned from deployments and industrial uses of AI and autonomy
</p></li>
    </ul>

    <p><strong>Security and Privacy of AI and Autonomous Systems</strong></p>
    <ul>
<li><p>
	Detecting dataset anomalies that lead to autonomous system security and privacy violations
</p></li>
<li><p>
	Detecting data poisoning, model poisoning and system attacks
</p></li>
<li><p>
	Differential privacy and privacy-preserving learning and generative models
</p></li>
<li><p>	
Adversarial attacks on AI and autonomy, and defenses against adversarial attacks
</p></li>
<li><p>
	Mitigation and improved resiliency of AI and autonomous systems to various forms of attacks
</p></li>
<li><p>
	Engineering trusted autonomous system and AI software architectures
</p></li>
<li><p>
	Red-teaming and stress testing of AI-enabled systems to identify vulnerabilities
</p></li>
<li><p>
	Real-world studies of security and privacy challenges for AI and autonomy
</p></li>
    </ul>
    
         </p>
         <h2> Paper Format </h2>
         <ul>
                    <li> Full papers (10 pages) </li>
                    <li> Work-in-progress papers (4 pages) </li>
                </ul>

                <h2> Submission Guidelines</h2>
                <p>
You are invited to submit regular papers (up to ten pages), or working papers (up to four pages), including references. To be considered, papers must be received by the submission deadline.
Submissions must be original work and may not be under submission to another venue at the time of review. Please mark all of your conflicts of interest when submitting your paper. Papers should be in IEEE conference format. 

                    Templates can be found at 
                  <a href="https://www.ieee.org/conferences/publishing/templates.html">https://www.ieee.org/conferences/publishing/templates.html</a>.
                </p>   
                <h2> Presentation Form</h2>
                <p>
                    All accepted submissions will be presented at the conference and are planned to be included in an IEEE conference proceedings. 
                    <!--
                    Due to time constraints, accepted papers will be selected for presentation as either talk or poster based on their review score and novelty. 
                    Nonetheless, all accepted papers should be considered as having equal importance.
                    -->
                    One author of each accepted paper is required to attend the conference and present the paper for it to be included in the proceedings. Please note that at least one author must register with the author (IEEE member or IEEE nonmember categories), even if the author is a student or otherwise. 
                </p> 
                
                <h2> Submission Website </h2>
                All presented papers (both full and working-length papers) will be published in the conference proceedings and submitted to the IEEE Xplore Digital Library.
                <p>
			
                To submit a full length paper or working paper, please go to our EasyChair submission site at:
                     <a href="https://easychair.org/conferences/?conf=icaa24">https://easychair.org/conferences/?conf=icaa24</a>
			     
                <!-- Please see EDAS Submission Site: <a href="https://edas.info/N30641">https://edas.info/N30641</a>  -->
                </p>


              <h2> Supported By</h2>
                <ul>
                    <li> <a href="https://iaa.jhu.edu"> The Johns Hopkins University Institute for Assured Autonomy </a>  </li>
                    <li> IEEE SMC <a href="https://www.ieeesmc.org/">The IEEE Systems, Man, and Cybernetics Society (SMC)</a> (Technical Co-Sponsor) </li>
                </ul>   

               <!--    <h2> Camera Ready Submission</h2>
                <p>
                All accepted papers need to be uploaded to the IEEE submission site. More details soon. 
                -->

                <!-- Below is the link to the 2024 IEEE International Conference on Assured Autonomy (ICAA) (ICAA 2023) Author Submission Site.

                <a href= "https://ieeecps.org/#!/auth/login?ak=1&pid=1yXaVmlecl3fJUuicuIka7">Camera Ready Submission Site</a>
                </p>    
                -->


                <h2> Contact Us </h2>
                <!-- <strong>ieee-icaa at googlegroups dot com</strong> -->
	        Please send comments and questions to auroraschmidt "at" gmail "dot" com.

    </div>
    </div>
</section>

<section id="keynotes">
    <div class="container">
        <div class="row">
            <h3 class="first">Keynote Speakers</h3>            
            
            <p>
		    <img src="alvaroheadshot.jpg" style="width: 2in;" alt="Picture of Dr. Alvaro Velasquez"><br>
		    Dr. Alvaro Velasquez, Keynote: October 11th<br>
Information Innovation Office (I2O), DARPA<br>
<br>
Alvaro Velasquez is a program manager at DARPA, where he currently leads programs on neuro-symbolic and adversarial AI. Before that, Alvaro oversaw the machine intelligence portfolio for the Information Directorate of the Air Force Research Laboratory (AFRL). Alvaro is a recipient of the distinguished paper award from AAAI and best paper and patent awards from AFRL. He has authored over 80 papers and two patents, serves as Associate Editor of the IEEE Transactions on Artificial Intelligence, and is a co-founder of the Neuro-symbolic Systems (NeuS) conference. Alvaro will present on the topic of, “Transferring Assured Autonomy from Abstraction to Reality.” Foundation models, including Chat-GPT and its many variants, have come into prominence in the natural language processing (NLP) community thanks the ubiquity of text data readily available on the internet and the design of modern transformer architectures that can effectively learn from such data. However, the development of a foundation model for autonomy is faced with additional challenges not present in NLP. In this talk, we discuss some of these challenges, how abstract-to-real autonomy transfer is a promising direction, and what the downstream implications of such transfer are in terms of preserving the assurance of systems from the source environment to the target. 
            </p>
            <p>
		    <img src="dragosheadshot.png" style="width: 2in;" alt="Picture of Dr. Dragos Margineantu"> <br>
Dr.  Dragos Margineantu, Keynote: October 10th<br>
Boeing AI Chief Technologist<br>
<br>
Dragos Margineantu is a Boeing Senior Technical Fellow and Artificial Intelligence (AI) Chief Technologist who is the technical lead of AI research and engineering in Boeing. His interests include computational methods for robust systems, autonomous commercial flight, anomaly and surprise detection & handling, reasoning under uncertainty, validation and testing of decision systems, cost-sensitive, active, ensemble learning, and inverse reinforcement learning. Dragos was one of the pioneers in research on ensemble learning and cost-sensitive learning and on statistical testing of learned models. At Boeing, he developed assurance methods for decision systems, machine learning based solutions for autonomous flight, airplane maintenance, airplane performance, surveillance, and security. Margineantu served as the Boeing principal investigator (PI) of multiple Defense Advanced Research Projects Agency (DARPA) projects and chaired major ML and data science conferences. Margineantu serves as the Action Editor for Special Issues for the Machine Learning Journal (MLj), edited by Springer. He co-advised graduate students at Massachusetts Institute of Technology (MIT) and KU Leuven in Belgium, served on Canada Research Chair committees, and on NSF review panels. Together with Mohamed Zaki and Sanjay Chawla, he started and co-chaired the Machine Learning Data Analytics Symposia (MLDAS) series since 2014. In his free time Dragos is coaching middle schoolers for mathematics competitions and enjoys nature photography. Dragos Margineantu earned a Ph.D. in Machine Learning from Oregon State University in 2001.

            </p>
        </div>

    </div>
</section>

